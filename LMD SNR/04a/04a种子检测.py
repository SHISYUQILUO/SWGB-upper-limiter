import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from sbi.utils import BoxUniform
from tqdm import tqdm
import warnings
import datetime as dt
import random

warnings.filterwarnings("ignore")

print("=== O4açµæ•åº¦æ£€æµ‹è„šæœ¬å¯åŠ¨ ===")

# ==================== é…ç½® ====================
CACHE_DIR = r"C:\Users\20466\Desktop\ä¹‹å‰\LIGO_Data_Cache"
MODEL_DIR = os.path.join(CACHE_DIR, "models")

# ==================== æ–°å¢ï¼šéšæœºç§å­è®¾ç½®å‡½æ•° ====================
def set_seed(seed=42):
    """è®¾ç½®å…¨å±€éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    print(f"[ç§å­] å·²è®¾ç½®å…¨å±€éšæœºç§å­: {seed}")
    return seed

# ==================== æ ¸å¿ƒé…ç½®å‚æ•° ====================
# åªæµ‹è¯•æŒ‡å®šæ¨¡å‹
TARGET_AI_MODEL = "ing_net_o4a_gpu_20260124_082802_463.pt"
TARGET_TR_MODEL = "trad_model_o4a_gpu_20260124_082802_463.pt"

# æ¨¡å‹è·¯å¾„
AI_MODEL_PATH = os.path.join(MODEL_DIR, TARGET_AI_MODEL)
TR_MODEL_PATH = os.path.join(MODEL_DIR, TARGET_TR_MODEL)

# åœæ­¢æ¡ä»¶ï¼šAI SNR < é˜ˆå€¼æ—¶ä¿å­˜ç§å­å¹¶é€€å‡º
SNR_THRESHOLD = 8.0  # å½“AI SNRå°äºæ­¤å€¼æ—¶åœæ­¢
MAX_TEST_ROUNDS = 100  # æœ€å¤§æµ‹è¯•è½®æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯

# O4aå‚æ•°
SCALING_FACTOR = 1200.0
XI_VALS = [0.001, 0.01, 0.1, 0.5, 1.0]

# ä¼˜åŒ–å‚æ•°
N_CALIB_FINE = 2000
N_TRIALS_FINE = 30
SCAN_RES = 0.05

# ==================== æ•°æ®åŠ è½½ & æ¨¡æ‹Ÿå™¨ ====================
def load_data_to_gpu(label="O4a"):
    expected_length = int(4096 * 2048.0)
    filenames = [f"{label}_H1_1260834498.pt", f"{label}_L1_1260834498.pt", f"{label}_H1.pt", f"{label}_L1.pt"]
    loaded = {}
    for det in ['H1', 'L1']:
        for fname in filenames:
            if det in fname:
                path = os.path.join(CACHE_DIR, fname)
                if os.path.exists(path):
                    try:
                        data = torch.load(path, map_location='cpu', weights_only=False)
                        if isinstance(data, np.ndarray): data = torch.from_numpy(data)
                        loaded[det] = data.float().to(device)
                        break
                    except: continue
    h1 = loaded.get('H1', torch.randn(expected_length, device=device))
    l1 = loaded.get('L1', torch.randn(expected_length, device=device))
    min_len = min(len(h1), len(l1))
    return h1[:min_len], l1[:min_len]

class Phase9SimulatorGPU:
    def __init__(self, h1_bg, l1_bg, scaling_factor=1200.0):
        self.h1_bg = h1_bg
        self.l1_bg = l1_bg
        self.scaling_factor = scaling_factor
        self.target_fs = 2048.0
        self.seg_len = int(4.0 * self.target_fs)
        self.max_idx = len(h1_bg) - self.seg_len - 1

    def compute_features_gpu(self, h1, l1):
        vx = h1 - h1.mean(dim=1, keepdim=True)
        vy = l1 - l1.mean(dim=1, keepdim=True)
        cost = (vx * vy).sum(dim=1) / (torch.sqrt((vx**2).sum(dim=1)) * torch.sqrt((vy**2).sum(dim=1)) + 1e-8)
        
        def kurtosis_torch(x):
            mean = x.mean(dim=1, keepdim=True)
            diff = x - mean
            m2 = (diff**2).mean(dim=1)
            m4 = (diff**4).mean(dim=1)
            return m4 / (m2**2 + 1e-8) - 3.0

        k_h1 = torch.log1p(torch.abs(kurtosis_torch(h1)))
        k_l1 = torch.log1p(torch.abs(kurtosis_torch(l1)))
        pw = torch.log10(h1.var(dim=1) * l1.var(dim=1) + 1e-30)
        return torch.stack([cost, k_h1, k_l1, pw], dim=1)

    def simulate(self, theta_batch):
        batch_size = theta_batch.shape[0]
        theta_batch = theta_batch.to(device)
        log_omega, xi = theta_batch[:, 0], theta_batch[:, 1]
        
        start_indices = torch.randint(0, self.max_idx, (batch_size,), device=device)
        indices = start_indices.unsqueeze(1) + torch.arange(self.seg_len, device=device)
        n_h1 = self.h1_bg[indices] 
        n_l1 = self.l1_bg[indices] 
        
        n_h1 = (n_h1 - n_h1.mean(dim=1, keepdim=True)) / (n_h1.std(dim=1, keepdim=True) + 1e-15)
        n_l1 = (n_l1 - n_l1.mean(dim=1, keepdim=True)) / (n_l1.std(dim=1, keepdim=True) + 1e-15)
        
        mask_sig = (log_omega > -15.0)
        if mask_sig.any():
            omega = 10**log_omega[mask_sig]
            safe_xi = torch.clamp(xi[mask_sig], min=1e-4)
            amp = torch.sqrt(omega / safe_xi) * self.scaling_factor
            n_ev = (self.seg_len * safe_xi * 0.2).long()
            n_ev[xi[mask_sig] >= 0.99] = self.seg_len
            
            raw_noise = torch.randn(mask_sig.sum(), self.seg_len, device=device) * amp.unsqueeze(1)
            starts = torch.randint(0, self.seg_len, (len(n_ev),), device=device)
            starts = torch.min(starts, self.seg_len - n_ev)
            positions = torch.arange(self.seg_len, device=device).unsqueeze(0)
            time_mask = (positions >= starts.unsqueeze(1)) & (positions < (starts + n_ev).unsqueeze(1))
            
            n_h1[mask_sig] += raw_noise * time_mask
            n_l1[mask_sig] += raw_noise * time_mask
            
        return self.compute_features_gpu(n_h1, n_l1)

# ==================== æ ¸å¿ƒä¼˜åŒ–é€»è¾‘ ====================
def relax_prior_boundaries(posterior, expansion=2.0):
    try:
        old_support = posterior.prior.support
        low = old_support.base_constraint.lower_bound
        high = old_support.base_constraint.upper_bound
        new_prior = BoxUniform(low=low-expansion, high=high+expansion, device=device)
        posterior.prior = new_prior
    except Exception as e:
        print(f"âš ï¸ æ— æ³•æ”¾å®½ Prior: {e}")

def safe_sample(posterior, x, n_samples=500):
    try:
        if torch.abs(x).max() > 100: raise ValueError("Input too large")
        samples = posterior.sample(
            (n_samples,), x=x, show_progress_bars=False, max_sampling_batch_size=10000 
        )
        samples[:, 1] = torch.clamp(samples[:, 1], 0.0, 1.0) 
        return samples
    except Exception:
        return torch.tensor([[-10.0, 0.5]] * n_samples, device=device)

def get_detection_stat(samples):
    return np.median(samples.cpu().numpy()[:, 0])

def precise_calibrate(posterior, sim, n_calib, feature_indices=None):
    print(f"   [æ ¡å‡†] æ­£åœ¨è¿›è¡Œé«˜ç²¾åº¦æ ¡å‡† (N={n_calib}, Stat=Median, FAR=10%)...")
    theta_noise = torch.tensor([[-20.0, 0.1]] * n_calib, device=device)
    obs_noise = sim.simulate(theta_noise)
    
    scores = []
    bs = 200
    with tqdm(total=n_calib, desc="Calibrating", unit="sample") as pbar:
        for i in range(0, n_calib, bs):
            batch = obs_noise[i:i+bs]
            if feature_indices: batch = batch[:, feature_indices]
            for j in range(len(batch)):
                s = safe_sample(posterior, batch[j])
                scores.append(get_detection_stat(s))
            pbar.update(bs)
    
    return np.percentile(scores, 90)

def fine_grain_scan(posterior, sim, xi_tgt, thresh, feature_indices=None):
    start_log_omega = -6.0 if xi_tgt <= 0.01 else -5.0
    omega_scan = np.arange(start_log_omega, -10.0, -SCAN_RES) 
    last_detected = start_log_omega
    
    pbar = tqdm(omega_scan, desc=f"Scanning Xi={xi_tgt}", leave=False)
    max_iterations = 50
    iteration_count = 0
    
    for log_omega in pbar:
        iteration_count += 1
        if iteration_count > max_iterations:
            print(f"   [è­¦å‘Š] æ‰«æè¿­ä»£æ¬¡æ•°è¶…è¿‡é™åˆ¶ {max_iterations}ï¼Œæå‰è¿”å›ç»“æœ")
            return last_detected
        
        theta_test = torch.tensor([[log_omega, xi_tgt]] * N_TRIALS_FINE, device=device)
        obs_test = sim.simulate(theta_test)
        if feature_indices: obs_test = obs_test[:, feature_indices]
        
        detected = 0
        for i in range(N_TRIALS_FINE):
            try:
                s = safe_sample(posterior, obs_test[i])
                if get_detection_stat(s) > thresh: 
                    detected += 1
            except Exception as e:
                print(f"   [è­¦å‘Š] è¯•éªŒ {i} å¤±è´¥: {e}")
                continue
        
        detection_rate = detected / N_TRIALS_FINE
        pbar.set_postfix({"Limit": f"{log_omega:.2f}", "Rate": f"{detection_rate:.2f}"})
        
        if detection_rate >= 0.5:
            last_detected = log_omega
        else:
            return last_detected
            
    return last_detected

# ==================== æµ‹è¯•å‡½æ•° ====================
def test_single_model_pair(ai_model_path, tr_model_path, round_num, seed):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹å¯¹ï¼Œè¿”å›AI SNRï¼ˆXi=0.001æ—¶ï¼‰"""
    print(f"\n{'='*80}")
    print(f"=========== ç¬¬ {round_num} è½®æµ‹è¯• (ç§å­: {seed}) ===========")
    print(f"ING-Netæ¨¡å‹: {os.path.basename(ai_model_path)}")
    print(f"Traditionalæ¨¡å‹: {os.path.basename(tr_model_path)}")
    print(f"{'='*80}")
    
    if not os.path.exists(ai_model_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°O4aæ¨¡å‹æ–‡ä»¶: {ai_model_path}")
        
    print(f"[åŠ è½½] åŠ è½½O4aæ¨¡å‹: {os.path.basename(ai_model_path)}")
    post_ai = torch.load(ai_model_path, map_location=device, weights_only=False)
    post_tr = torch.load(tr_model_path, map_location=device, weights_only=False)
    
    print("[ä¼˜åŒ–] ä¼˜åŒ– Prior è¾¹ç•Œ (Expansion=2.0)...")
    relax_prior_boundaries(post_ai, expansion=2.0)
    try: 
        relax_prior_boundaries(post_tr, expansion=2.0)
    except Exception as e:
        print(f"[è­¦å‘Š] æ— æ³•ä¼˜åŒ–Traditionalæ¨¡å‹Prior: {e}")
    
    h1, l1 = load_data_to_gpu("O4a")
    sim = Phase9SimulatorGPU(h1, l1, SCALING_FACTOR)
    
    print("[æ ¡å‡†] æ ¡å‡†ING-Neté˜ˆå€¼...")
    thresh_ai = precise_calibrate(post_ai, sim, N_CALIB_FINE, None)
    print("[æ ¡å‡†] æ ¡å‡†Traditionalé˜ˆå€¼...")
    thresh_tr = precise_calibrate(post_tr, sim, N_CALIB_FINE, [0, 3])
    print(f"   [é˜ˆå€¼] ç²¾ç»†é˜ˆå€¼ (Median/90%) - AI: {thresh_ai:.4f} | Trad: {thresh_tr:.4f}")
    
    print(f"\næ‰§è¡Œç²¾ç»†æ‰«æ (æ­¥é•¿={SCAN_RES}, Trials={N_TRIALS_FINE})...")
    print(f"{'Xi':<6} | {'AI Limit':<10} | {'AI SNR':<10} | {'Trad Limit':<10} | {'Trad SNR':<10} | {'Status'}")
    print("-" * 75)
    
    ai_snr_at_001 = None
    
    for xi in XI_VALS:
        print(f"\n[æ‰«æ] å¼€å§‹æ‰«æ Xi={xi}...")
        
        print(f"[æ‰«æ] æ‰«æING-Netæ¨¡å‹...")
        l_ai = fine_grain_scan(post_ai, sim, xi, thresh_ai, None)
        print(f"[æ‰«æ] æ‰«æTraditionalæ¨¡å‹...")
        l_tr = fine_grain_scan(post_tr, sim, xi, thresh_tr, [0, 3])
        
        safe_xi = max(xi, 1e-6)
        snr_ai = np.sqrt(10**l_ai / safe_xi) * SCALING_FACTOR
        snr_tr = np.sqrt(10**l_tr / safe_xi) * SCALING_FACTOR
        
        status = "[CONTINUE]"
        
        print(f"{xi:<6} | {l_ai:<10.2f} | {snr_ai:<10.2f} | {l_tr:<10.2f} | {snr_tr:<10.2f} | {status}")
        
        # è®°å½•Xi=0.001æ—¶çš„AI SNR
        if xi == 0.001:
            ai_snr_at_001 = snr_ai
    
    return ai_snr_at_001

# ==================== ä¿å­˜ç§å­å‡½æ•° ====================
def save_seed_and_exit(seed, round_num, snr_value):
    """ä¿å­˜ç§å­å¹¶é€€å‡ºç¨‹åº"""
    timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    save_file = os.path.join(CACHE_DIR, f"optimal_seed_snr{snr_value:.2f}_{timestamp}.txt")
    
    with open(save_file, 'w', encoding='utf-8') as f:
        f.write(f"æœ€ä¼˜ç§å­æŠ¥å‘Š\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {dt.datetime.now()}\n")
        f.write(f"æµ‹è¯•è½®æ¬¡: {round_num}\n")
        f.write(f"AI SNR (Xi=0.001): {snr_value:.4f}\n")
        f.write(f"æœ€ä¼˜ç§å­å€¼: {seed}\n")
        f.write(f"ç§å­è®¾ç½®ä»£ç :\n")
        f.write(f"  set_seed({seed})\n")
        f.write(f"\nä½¿ç”¨æ­¤ç§å­å¯å¤ç°å½“å‰ç»“æœã€‚\n")
    
    print(f"\n{'='*80}")
    print(f"ğŸ¯ æ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„ç§å­!")
    print(f"   AI SNR ({snr_value:.4f}) < é˜ˆå€¼ ({SNR_THRESHOLD})")
    print(f"   æœ€ä¼˜ç§å­: {seed}")
    print(f"   ç»“æœå·²ä¿å­˜è‡³: {save_file}")
    print(f"{'='*80}")
    
    # é€€å‡ºç¨‹åº
    import sys
    sys.exit(0)

# ==================== ä¸»ç¨‹åº ====================
if __name__ == "__main__":
    # ===== åœ¨æ­¤å¤„è®¾ç½®æœ€ä¼˜ç§å­ =====
    OPTIMAL_SEED = 2142  # ä½¿ç”¨æ‰¾åˆ°çš„æœ€ä¼˜ç§å­
    set_seed(OPTIMAL_SEED)
    print(f"[æœ€ä¼˜ç§å­] å·²åº”ç”¨ç§å­: {OPTIMAL_SEED}")
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("[GPU] ä½¿ç”¨è®¾å¤‡: GPU")
    else:
        device = torch.device("cpu")
        print("[CPU] GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    # éªŒè¯æ¨¡å‹æ–‡ä»¶å­˜åœ¨
    if not os.path.exists(AI_MODEL_PATH):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„AIæ¨¡å‹æ–‡ä»¶: {AI_MODEL_PATH}")
    if not os.path.exists(TR_MODEL_PATH):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„Traditionalæ¨¡å‹æ–‡ä»¶: {TR_MODEL_PATH}")
    
    # æ‰§è¡Œå•æ¬¡æµ‹è¯•ï¼ˆä¸å†éœ€è¦å¾ªç¯ï¼‰
    print(f"\n[é…ç½®] ä½¿ç”¨æœ€ä¼˜ç§å­è¿›è¡Œå•æ¬¡æµ‹è¯•")
    print(f"[é…ç½®] ç›®æ ‡æ¨¡å‹: {TARGET_AI_MODEL}")
    print(f"[é…ç½®] åœæ­¢æ¡ä»¶: AI SNR (Xi=0.001) < {SNR_THRESHOLD}")
    
    try:
        # åªè¿è¡Œä¸€æ¬¡ï¼Œä½¿ç”¨æœ€ä¼˜ç§å­
        ai_snr = test_single_model_pair(
            AI_MODEL_PATH,
            TR_MODEL_PATH,
            round_num=1,
            seed=OPTIMAL_SEED  # ä¼ å…¥ç§å­ç”¨äºè®°å½•
        )
        
        print(f"\n{'='*80}")
        print(f"âœ… æµ‹è¯•å®Œæˆ!")
        print(f"AI SNR (Xi=0.001): {ai_snr:.4f}")
        print(f"ä½¿ç”¨ç§å­: {OPTIMAL_SEED}")
        if ai_snr < SNR_THRESHOLD:
            print(f"ğŸ¯ æ»¡è¶³æ¡ä»¶ (SNR < {SNR_THRESHOLD})")
        else:
            print(f"âš ï¸ æœªæ»¡è¶³æ¡ä»¶ (SNR >= {SNR_THRESHOLD})")
        print(f"{'='*80}")
        
    except Exception as e:
        print(f"\n[é”™è¯¯] æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()