# @title Phase 12 (Evaluation): Load Seed 4040 Model & 10-Round Test
import os
import sys
import warnings
import numpy as np
import torch
import matplotlib.pyplot as plt
from scipy.stats import kurtosis, pearsonr
import scipy.signal as signal
import re
from sbi.inference import SNPE
from sbi.utils import BoxUniform
from tqdm import tqdm

# --- 1. åŸºç¡€é…ç½® ---
warnings.filterwarnings('ignore')
device = "cuda" if torch.cuda.is_available() else "cpu"

# ==========================================
# [é…ç½®åŒºåŸŸ] è·¯å¾„è®¾ç½®
# ==========================================
# 1. åŸå§‹ O3a æ•°æ®è·¯å¾„ (è¯·ç¡®ä¿è¿™äº›æ–‡ä»¶å­˜åœ¨)
H1_FILE = r"C:\Users\20466\Desktop\upper limiter\ligo_o3b_data\O3a_H1_1243436468.pt"
L1_FILE = r"C:\Users\20466\Desktop\upper limiter\ligo_o3b_data\O3a_L1_1243436468.pt"

# 2. [å…³é”®] å·²è®­ç»ƒæ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ (ä½ æä¾›çš„è·¯å¾„)
MODEL_DIR = r"C:\Users\20466\Desktop\ä¹‹å‰ - å‰¯æœ¬\Results_O3a_Seed4040_Analysis\Models_Seed_4040_20260209"

# 3. ç»“æœä¿å­˜è·¯å¾„ (ä¿å­˜ç”Ÿæˆçš„10å¼ å›¾ç‰‡)
RESULTS_DIR = os.path.join(MODEL_DIR, "Evaluation_10_Rounds_Output")
if not os.path.exists(RESULTS_DIR): os.makedirs(RESULTS_DIR)

print(f"[Phase 12 - Evaluation Only] å¼€å§‹è¿è¡Œ | è®¾å¤‡: {device}")
print(f"æ¨¡å‹åŠ è½½è·¯å¾„: {MODEL_DIR}")
print(f"ç»“æœä¿å­˜è·¯å¾„: {RESULTS_DIR}")

# ==========================================
# [æ ¸å¿ƒ] é²æ£’ç™½åŒ–å‡½æ•° (ä¿æŒä¸€è‡´)
# ==========================================
def robust_whiten(data, fs=2048, fftlength=2.0):
    nperseg = int(fftlength * fs)
    freqs, psd = signal.welch(data, fs=fs, nperseg=nperseg, average='median')
    asd = np.sqrt(psd)
    data_fft = np.fft.rfft(data)
    fft_freqs = np.fft.rfftfreq(len(data), d=1.0/fs)
    interp_asd = np.exp(np.interp(np.log(fft_freqs[1:]), np.log(freqs[1:]), np.log(asd[1:])))
    interp_asd = np.insert(interp_asd, 0, interp_asd[0])
    whitened_fft = data_fft / (interp_asd + 1e-30)
    whitened_data = np.fft.irfft(whitened_fft, n=len(data))
    return whitened_data / np.std(whitened_data)

# ==========================================
# 2. æ•°æ®å‡†å¤‡ (åŠ è½½æµ‹è¯•é›†)
# ==========================================
print("\n>>> [1/4] åŠ è½½ O3a æ•°æ®æ–‡ä»¶...")

if not os.path.exists(H1_FILE) or not os.path.exists(L1_FILE):
    print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ° O3a æ•°æ®æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„:\n{H1_FILE}")
    sys.exit()

full_h1 = torch.load(H1_FILE, map_location='cpu')
full_l1 = torch.load(L1_FILE, map_location='cpu')

if isinstance(full_h1, torch.Tensor): full_h1 = full_h1.numpy().flatten()
if isinstance(full_l1, torch.Tensor): full_l1 = full_l1.numpy().flatten()

# åˆ’åˆ†æµ‹è¯•é›† (ååŠéƒ¨åˆ†)
min_len = min(len(full_h1), len(full_l1))
mid_point = min_len // 2
test_h1, test_l1 = full_h1[mid_point:], full_l1[mid_point:]
print(f"    æµ‹è¯•é›†æ•°æ®å°±ç»ª: {len(test_h1)/2048:.1f}s")

# ==========================================
# 3. åŠ è½½æ¨¡å‹
# ==========================================
print(f"\n>>> [2/4] ä»æŒ‡å®šæ–‡ä»¶å¤¹åŠ è½½ Seed 4040 æ¨¡å‹...")

# æ„é€ æ–‡ä»¶å (åŸºäºä¹‹å‰çš„å‘½åé€»è¾‘)
ai_model_path = os.path.join(MODEL_DIR, "model_ai_seed_4040.pth")
trad_model_path = os.path.join(MODEL_DIR, "model_trad_seed_4040.pth")

if not os.path.exists(ai_model_path):
    print(f"âŒ é”™è¯¯ï¼šåœ¨æ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ° {ai_model_path}")
    print("è¯·æ£€æŸ¥æ–‡ä»¶å¤¹å†…æ–‡ä»¶åæ˜¯å¦ä¸º 'model_ai_seed_4040.pth'")
    sys.exit()

# å®šä¹‰å…ˆéªŒ (ç”¨äºæ„å»ºåéªŒå¯¹è±¡)
prior = BoxUniform(low=torch.tensor([-25.0, 0.001], device=device), 
                   high=torch.tensor([-5.0, 1.0], device=device))

try:
    # 1. åŠ è½½å¯†åº¦ä¼°è®¡å™¨ (Density Estimator)
    de_ai = torch.load(ai_model_path, map_location=device)
    de_trad = torch.load(trad_model_path, map_location=device)
    
    # 2. é‡å»ºåéªŒå¯¹è±¡ (Posterior)
    # ä½¿ç”¨ç©ºçš„ SNPE å®ä¾‹æ¥æ„å»ºåéªŒ
    inference_loader = SNPE(prior=prior, device=device)
    post_ai = inference_loader.build_posterior(de_ai, sample_with='direct')
    post_trad = inference_loader.build_posterior(de_trad, sample_with='direct')
    
    print("    âœ… æ¨¡å‹åŠ è½½å¹¶é‡ç»„æˆåŠŸï¼")

except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    sys.exit()

# ==========================================
# 4. æ‰§è¡Œ 10 è½®æµ‹è¯•å¹¶ç»˜å›¾
# ==========================================
print(f"\n>>> [3/4] å¼€å§‹ 10 è½®éšæœºæ€§æµ‹è¯•ä¸è¯„ä»·...")

NUM_ROUNDS = 10         # ä¿®æ”¹ï¼šè¿è¡Œ 10 æ¬¡
TESTS_PER_ROUND = 50    # æ¯è½®æµ‹è¯• 50 ä¸ªæ ·æœ¬ (å¯æ ¹æ®é€Ÿåº¦è°ƒæ•´)
seg_len = 8192
max_idx_test = len(test_h1) - seg_len

# ç¡®ä¿éšæœºæ€§ (é‡Šæ”¾ç§å­)
np.random.seed(None)

for round_idx in range(1, NUM_ROUNDS + 1):
    print(f"\n--- [Round {round_idx}/{NUM_ROUNDS}] ---")
    
    ul_ai_list = []
    ul_trad_list = []
    
    # --- æ‰¹é‡æµ‹è¯• ---
    for i in tqdm(range(TESTS_PER_ROUND), desc=f"Testing Round {round_idx}", leave=False):
        # 1. éšæœºåˆ‡ç‰‡
        start_idx = np.random.randint(0, max_idx_test)
        slice_h1 = test_h1[start_idx : start_idx + seg_len].copy()
        slice_l1 = test_l1[start_idx : start_idx + seg_len].copy()
        
        # 2. é¢„å¤„ç†
        slice_h1 = robust_whiten(slice_h1, fs=2048)
        slice_l1 = robust_whiten(slice_l1, fs=2048)
        
        # 3. ç‰¹å¾æå–
        cc, _ = pearsonr(slice_h1, slice_l1)
        k_h1 = np.log1p(np.abs(kurtosis(slice_h1)))
        k_l1 = np.log1p(np.abs(kurtosis(slice_l1)))
        p = np.log10(np.var(slice_h1) * np.var(slice_l1) + 1e-30)
        
        obs_full = torch.tensor([cc, k_h1, k_l1, p], dtype=torch.float32).to(device)
        obs_trad = torch.tensor([cc, p], dtype=torch.float32).to(device)
        
        # 4. æ¨æ–­ (Inference)
        # é‡‡æ · 1000 ä¸ªåéªŒç‚¹ï¼Œå– 95% åˆ†ä½æ•°ä¸ºä¸Šé™
        s_ai = post_ai.sample((1000,), x=obs_full, show_progress_bars=False)
        ul_ai_val = np.percentile(s_ai.cpu().numpy()[:, 0], 95)
        ul_ai_list.append(ul_ai_val)
        
        s_trad = post_trad.sample((1000,), x=obs_trad, show_progress_bars=False)
        ul_trad_val = np.percentile(s_trad.cpu().numpy()[:, 0], 95)
        ul_trad_list.append(ul_trad_val)

    # --- ç»Ÿè®¡ç»“æœ ---
    mean_ai = np.mean(ul_ai_list)
    mean_trad = np.mean(ul_trad_list)
    improvement = 10**mean_trad / 10**mean_ai
    
    print(f"    > Round {round_idx} Result: Trad=10^{mean_trad:.2f} | AI=10^{mean_ai:.2f} | Improvement={improvement:.2f}x")

    # --- ç»˜å›¾ä¸ä¿å­˜ ---
    plt.figure(figsize=(10, 6))
    
    # ç»˜åˆ¶ç›´æ–¹å›¾
    plt.hist(ul_ai_list, bins=15, density=True, alpha=0.6, color='royalblue', label=f'ING-Net (Seed 4040)')
    plt.hist(ul_trad_list, bins=15, density=True, alpha=0.6, color='darkorange', label='Traditional Baseline')
    
    # ç»˜åˆ¶å‡å€¼çº¿
    plt.axvline(mean_ai, color='blue', linestyle='--', linewidth=2, label=f'AI Mean: {mean_ai:.2f}')
    plt.axvline(mean_trad, color='darkorange', linestyle='--', linewidth=2, label=f'Trad Mean: {mean_trad:.2f}')
    
    # å›¾è¡¨è£…é¥°
    plt.xlabel(r'95% Upper Limit ($\log_{10}\Omega$)', fontsize=14)
    plt.ylabel('Density', fontsize=14)
    plt.title(f'Evaluation Round {round_idx}/10: Sensitivity Comparison\n(Improvement Factor: {improvement:.2f}x)', fontsize=15)
    plt.legend(fontsize=12, loc='upper left')
    plt.grid(True, alpha=0.3, linestyle='--')
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_filename = f"Eval_Round_{round_idx:02d}_Seed4040.png"
    save_path = os.path.join(RESULTS_DIR, save_filename)
    plt.savefig(save_path, dpi=300)
    plt.close() # å…³é—­ç”»å¸ƒï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    
    print(f"    ğŸ–¼ï¸ å›¾ç‰‡å·²ä¿å­˜: {save_path}")

print(f"\n{'='*60}")
print(f"ğŸ‰ å…¨éƒ¨ 10 è½®æµ‹è¯•å®Œæˆï¼")
print(f"ğŸ“‚ æ‰€æœ‰å›¾ç‰‡ä¿å­˜åœ¨: {RESULTS_DIR}")
print(f"{'='*60}")