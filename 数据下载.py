#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIGO æ•°æ®è‡ªåŠ¨ä¸‹è½½è„šæœ¬
- éšæœºé€‰æ‹© GPS æ—¶é—´ï¼ˆåŸºäº O3a/O3b/O4a å¤§è‡´æ—¶æ®µï¼‰
- å¾ªç¯ä¸‹è½½ 4 ä¸ªæ‰¹æ¬¡
- ä¸¥æ ¼æ ¡éªŒ H1/L1 æ—¶é—´åŒ¹é…ï¼Œä¸åŒ¹é…åˆ™é‡è¯•
- ä¿å­˜ä¸º .pt æ ¼å¼ï¼ˆä¸æ‚¨çš„å›¾ç‰‡å‘½åä¸€è‡´ï¼‰
"""

import numpy as np
import torch
from gwpy.timeseries import TimeSeries
import os
import time

# ==================== é…ç½® ====================
OUTPUT_DIR = "./ligo_data"
DURATION = 4096       # æ•°æ®é•¿åº¦ï¼ˆç§’ï¼‰ï¼Œçº¦ 1.1 å°æ—¶ï¼Œä¸æ‚¨çš„æ–‡ä»¶å¤§å°(~64MB)åŒ¹é…
SAMPLE_RATE = 4096    # é‡‡æ ·ç‡ 4KHzï¼ˆå¦‚éœ€ 16KHz å¯æ”¹ä¸º 16384ï¼Œä½†æ–‡ä»¶ä¼šæ›´å¤§ï¼‰

# å„è§‚æµ‹æ®µçš„ä¸­å¿ƒ GPS æ—¶é—´å’Œåˆç†èŒƒå›´ï¼ˆåŸºäºæ‚¨çš„å›¾ç‰‡ï¼‰
DATASET_RANGES = {
    'O3a': {
        'center_gps': 1238166018,  # 2019-05-07
        'start_gps': 1238166018 - 30*24*3600,  # Â±30å¤©
        'end_gps': 1238166018 + 30*24*3600,
        'description': 'O3a (Apr-Oct 2019)'
    },
    'O3b': {
        'center_gps': 1260834498,  # 2019-11-08
        'start_gps': 1260834498 - 30*24*3600,
        'end_gps': 1260834498 + 30*24*3600,
        'description': 'O3b (Nov 2019-Mar 2020)'
    },
    'O4a': {
        'center_gps': 1377415818,  # 2023-09-14
        'start_gps': 1377415818 - 60*24*3600,  # O4a èŒƒå›´æ›´å¤§
        'end_gps': 1377415818 + 60*24*3600,
        'description': 'O4a (May 2023-Jan 2024)'
    }
}

os.makedirs(OUTPUT_DIR, exist_ok=True)

def download_segment(detector, gps_start, duration, sample_rate):
    """
    ä¸‹è½½å•ä¸ªæ¢æµ‹å™¨æ•°æ®ï¼Œå¸¦é”™è¯¯å¤„ç†
    """
    try:
        print(f"    ä¸‹è½½ {detector} @ GPS {int(gps_start)}...")
        data = TimeSeries.fetch_open_data(
            detector, 
            gps_start, 
            gps_start + duration, 
            sample_rate=sample_rate,
            format='hdf5'
        )
        return data
    except Exception as e:
        print(f"    âš ï¸ {detector} ä¸‹è½½å¤±è´¥: {str(e)[:60]}")
        return None

def validate_and_save(h1_data, l1_data, dataset, gps_start, batch_num):
    """
    éªŒè¯ H1/L1 æ—¶é—´åŒ¹é…ï¼Œä¿å­˜ä¸º .pt
    """
    if h1_data is None or l1_data is None:
        return False
    
    # ä¸¥æ ¼æ ¡éªŒæ—¶é—´å¯¹é½ï¼ˆèµ·å§‹æ—¶é—´å·® < 1 ç§’ï¼‰
    h1_start = float(h1_data.t0.value)
    l1_start = float(l1_data.t0.value)
    time_diff = abs(h1_start - l1_start)
    
    if time_diff > 1.0:
        print(f"  âŒ æ—¶é—´ä¸åŒ¹é…ï¼H1:{h1_start:.0f}, L1:{l1_start:.0f}, å·®å€¼:{time_diff:.1f}s")
        return False
    
    # æ ¡éªŒæ•°æ®é•¿åº¦ä¸€è‡´
    if len(h1_data) != len(l1_data):
        print(f"  âŒ é•¿åº¦ä¸åŒ¹é…ï¼H1:{len(h1_data)}, L1:{len(l1_data)}")
        return False
    
    # è½¬æ¢ä¸º Tensor
    h1_tensor = torch.from_numpy(h1_data.value).float()
    l1_tensor = torch.from_numpy(l1_data.value).float()
    
    # æ–‡ä»¶åæ ¼å¼ï¼šDataset_H1_GPS.pt / Dataset_L1_GPS.pt
    # å¦‚æœ batch_num > 0ï¼Œæ·»åŠ åç¼€å¦‚ _4ï¼ˆä¸æ‚¨å›¾ç‰‡ä¸­çš„ O3b_..._4 ä¸€è‡´ï¼‰
    suffix = f"_{batch_num}" if batch_num > 0 else ""
    
    h1_filename = f"{dataset}_H1_{int(gps_start)}{suffix}.pt"
    l1_filename = f"{dataset}_L1_{int(gps_start)}{suffix}.pt"
    
    h1_path = os.path.join(OUTPUT_DIR, h1_filename)
    l1_path = os.path.join(OUTPUT_DIR, l1_filename)
    
    torch.save(h1_tensor, h1_path)
    torch.save(l1_tensor, l1_path)
    
    print(f"  âœ… æˆåŠŸä¿å­˜: {h1_filename} ({len(h1_tensor)/SAMPLE_RATE/3600:.2f}h)")
    print(f"           {l1_filename}")
    return True

def get_random_gps(dataset):
    """åœ¨æœ‰æ•ˆèŒƒå›´å†…ç”Ÿæˆéšæœº GPS æ—¶é—´"""
    info = DATASET_RANGES[dataset]
    return np.random.randint(info['start_gps'], info['end_gps'])

def download_dataset_batches(dataset, n_batches=4, max_retries=20):
    """
    ä¸ºæŸä¸ªæ•°æ®é›†ä¸‹è½½ n ä¸ªæ‰¹æ¬¡ï¼Œç¡®ä¿ H1/L1 å¯¹åº”
    """
    print(f"\n{'='*60}")
    print(f"å¼€å§‹ä¸‹è½½ {DATASET_RANGES[dataset]['description']}")
    print(f"ç›®æ ‡: {n_batches} ä¸ªåŒ¹é…æ‰¹æ¬¡ (H1+L1)")
    print(f"{'='*60}")
    
    successful_batches = 0
    attempts = 0
    
    while successful_batches < n_batches and attempts < max_retries:
        attempts += 1
        
        # ç”Ÿæˆéšæœº GPS æ—¶é—´ï¼ˆç¡®ä¿åœ¨æ•°æ®æ®µå†…ä¸”é¿å¼€è¾¹ç¼˜ï¼‰
        gps_start = get_random_gps(dataset)
        
        print(f"\n[å°è¯• {attempts}/{max_retries}] {dataset} æ‰¹æ¬¡ {successful_batches+1}/{n_batches}")
        print(f"  GPS æ—¶é—´: {gps_start} ({time.strftime('%Y-%m-%d %H:%M', time.gmtime(1238166018 + (gps_start-1238166018)))})")
        
        # ä¸‹è½½ H1 å’Œ L1
        h1 = download_segment('H1', gps_start, DURATION, SAMPLE_RATE)
        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        l1 = download_segment('L1', gps_start, DURATION, SAMPLE_RATE)
        
        # éªŒè¯å¹¶ä¿å­˜
        if validate_and_save(h1, l1, dataset, gps_start, batch_num=successful_batches+1):
            successful_batches += 1
            time.sleep(1)  # æˆåŠŸä¸‹è½½åçŸ­æš‚ä¼‘æ¯
        else:
            print(f"  ğŸ”„ è¯¥æ‰¹æ¬¡æ— æ•ˆï¼Œé‡æ–°é€‰æ‹© GPS æ—¶é—´...")
            time.sleep(0.5)
    
    if successful_batches < n_batches:
        print(f"âš ï¸ è­¦å‘Š: {dataset} ä»…å®Œæˆ {successful_batches}/{n_batches} æ‰¹æ¬¡")
    else:
        print(f"âœ… {dataset} å…¨éƒ¨ {n_batches} æ‰¹æ¬¡ä¸‹è½½å®Œæˆï¼")
    
    return successful_batches

# ==================== ä¸»ç¨‹åº ====================

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import gwpy
    except ImportError:
        print("è¯·å…ˆå®‰è£… gwpy: pip install gwpy")
        exit(1)
    
    print("LIGO æ•°æ®è‡ªåŠ¨ä¸‹è½½å·¥å…·")
    print(f"æ•°æ®ä¿å­˜ç›®å½•: {os.path.abspath(OUTPUT_DIR)}")
    print(f"æ¯æ®µæ—¶é•¿: {DURATION/3600:.1f} å°æ—¶, é‡‡æ ·ç‡: {SAMPLE_RATE}Hz")
    
    # åªä¸‹è½½ O3a æ•°æ®é›†ï¼Œ6ä¸ªæ‰¹æ¬¡
    all_datasets = ['O3a']
    
    total_stats = {}
    for ds in all_datasets:
        count = download_dataset_batches(ds, n_batches=6, max_retries=30)
        total_stats[ds] = count
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print("ä¸‹è½½å®Œæˆç»Ÿè®¡:")
    for ds, count in total_stats.items():
        status = "âœ… å®Œæˆ" if count == 4 else "âš ï¸ éƒ¨åˆ†"
        print(f"  {ds}: {count}/4 æ‰¹æ¬¡ {status}")
    
    print(f"\næ–‡ä»¶åˆ—è¡¨:")
    files = sorted([f for f in os.listdir(OUTPUT_DIR) if f.endswith('.pt')])
    for f in files:
        size = os.path.getsize(os.path.join(OUTPUT_DIR, f)) / 1024 / 1024
        print(f"  {f} ({size:.1f} MB)")